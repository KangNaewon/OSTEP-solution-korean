1.  시간을 재기위해서는 gettimeofday()를 통해서 만들 수 있는 타이머를 사용해야 할 것이다. 
    이 타이머는 얼마나 정확한가? 시간을 정확하게 재기 위해서는 타이머가얼마나 길어야 하는가?
    (반복문 내에서 몇 번이나 페이지를 접근해야 시간을 정확히 잴 수 있는지를 결정하는 데 도움을 줄 것이다)

A.  

2.  tlb.c 라는 프로그램을 작성하여 각 페이지를 접근하는 데 드는 대략적인 비용을 측정해 보자. 
    프로그램의 입력 값은 접근해야 하는 페이지들의 수와 시도 횟수이다.

A.  

3.  선호하는 스크립트 언어(csh, python 등)를 사용하여 프로그램을 실행시키는 스크립트를 작성하여 접근하는 페이지들의 수를 1부터 수천까지 2의 배수로 증가시키도록 해 보자.
    다른 기계들에서 스크립트를 실행하여 데이터를 수집하자. 신뢰할 수 있는 측정치를 얻기 위해서는 몇 번이나 시도해 봐야 하는가?

A.  


4.  그 다음으로 결과들을 사용하여 앞서 보인 그래프처럼 만들어 보자. 
    ploticus와 같은 툴을 사용하면 된다. 시각화하는 것은 데이터를 좀 더 잘 이해하는 데 도움이 되는데, 왜 그런 것 같은가?

A.  


5.  한 가지 주의해야 할 것은 컴파일러 최적화이다. 
    컴파일러는 프로그램의 다른 부분들이 사용하지 않는 변수를 반복문을 통해 증가시키는 부분을 빼버리는 등의 온밖 교묘한 짓들을 한다. 
    컴파일러가 작성한 TLB 크기 추정기를 어떻게 수정하여야 컴파일러가 주 반복문을 제거하지 않도록 만들 수 있을까?

A.  


6.  또 한 가지 주의해야 할 것은 대부분의 시스템은 CPU가 여러 개이며, 각 CPU는 물론 각각의 TLB 계층을 밖고 있다. 
    정말 제대로 측정하기 위해서는 스케줄러가 하나의 CPU에서 또 다른 CPU로 이동시키지 못하도록 만들어서 하나의 CPU만을 사용해서 측정해야 할 것이다. 
    어떻게 그렇게 할 수 있을까? (힌트 : 구글에서 “쓰레드 고정하기 (pinning a thread)”를 검색해 보자) 
    이렇게 하지 않았을 때는 어떤 일이 발생할까? 그리고 코드가 한 CPU에서 다른 CPU로 이동할 때 어떤 일이 발생할까?

A.  


7.  또 다른 발생할 수 있는 문제는 초기화와 관련되어 있다. 접근하기 전에 배열 a를 초기화하지 않는다면, 
    처음 a의 배열을 접근할 경우 한 번도 접근한 적이 없기 때문에 매우 비싼 비용이 들 것이다.이 부분이 시간을 재는데에 영향을 줄까? 
    이러한 잠재적인 비용 요인의 균형을 잡기 위해서 무엇을 할 수 있을까?

A.  

